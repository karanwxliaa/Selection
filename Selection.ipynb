{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Histopathological Image Analysis Competition Overview\n",
        "\n",
        "Welcome to the Histopathological Image Analysis Competition! In this competition, you will be working with histopathological images to complete a series of tasks designed to assess your skills in data preprocessing, image classification, generative networks, and graph-based networks.\n",
        "\n",
        "## Tasks\n",
        "\n",
        "1. **Load, preprocess, and augment data**\n",
        "2. **Classify images as cancerous or non-cancerous**\n",
        "3. **Generate cancerous images from non-cancerous images using generative networks**\n",
        "4. **Utilize Graph Convolutional Networks (GCNs) to analyze nucleus features**\n",
        "\n",
        "## Important Information\n",
        "\n",
        "- **Platform:** Google Colab\n",
        "- **Dataset:** [Histopathological Cancer Detection - Cropped](https://drive.google.com/drive/folders/1T4De029U-OJAEEHCbym_efc2mdFox6S5?usp=sharing)\n",
        "(Additionally can be found on kaggle https://www.kaggle.com/datasets/drbeane/hcd-cropped/data)\n",
        "- **Code Examples:** [Kaggle Code Examples](https://www.kaggle.com/datasets/drbeane/hcd-cropped/code)\n",
        "- **Submission Deadline:** Before Friday\n",
        "- **Reference Paper** (needed for step 4 and maybe 3): [Learning Shape-Aware Features with Generative Models for Nuclei Classification](https://arxiv.org/abs/2302.11416)\n",
        "- **Reference Code from the paper:** [SENUCLS](https://github.com/Lewislou/SENUCLS/tree/main)\n",
        "\n",
        "## Evaluation Criteria\n",
        "\n",
        "The evaluation for this assignment is **not based on accuracy** or **performance metrics** but on **how you approach the problem**. Since the problem statement is very abstract and can be solved in multiple ways, your methodology and creativity are key.\n",
        "\n",
        "## Tasks Details\n",
        "\n",
        "### Task 1: Load, preprocess, and augment data\n",
        "\n",
        "Use only 500 samples from the training data, idc about the accuracy and performance so don't waste time on that :)\n",
        "\n",
        "### Task 2: Classify if the image is cancerous or non-cancerous\n",
        "\n",
        "Use any classification model of your choice. Don't spend too much time on this; focus on the approach **after step 2.**\n",
        "\n",
        "### Task 3: Generate cancerous images from non-cancerous images using generative networks\n",
        "Here's where the competition begins,\n",
        "Use Any type of generative network (i'd prefer gans & diffusion models) to take the NON CANCEROUS images as input and generate an output of how this image would look like if it was cancerous.\n",
        "(eg: Non-cancerous image -> GAN -> Cancerous image)\n",
        "Don't focus on tuning the gan and increasing the accuracy I will mainly evaluate the approach.\n",
        "\n",
        "\n",
        "\n",
        "### Task 4: Utilize Graph Convolutional Networks (GCNs) to analyze nucleus features\n",
        "\n",
        "Incorporate strategies from the reference paper and,\n",
        "Utilize GCN / graph based networks.\n",
        "The key idea is to learn nucleus features based on structure, texture, and edge at the nuclei level first and then move to inter-nuclear graphs (see paper;mentioned above).\n",
        "\n",
        "\n",
        "## ** Important Note. **\n",
        "Now i get that this might be too much to process but take your time, use any AI or reference or tool you want to and *please please please* dont focus on accuracy or metrics (this doesnt mean that you get reckless metrics but the bare minimum would work, dont tune the results instead focus on the approach), I want to evaluate your approach. If you've completed everything and have time before friday then sure feel free to improve the metrics for brownie points.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cM3a-tWmcvZW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Starter Code\n",
        "\n",
        "## Obviously this is the VERY BASIC structure of the code with minimal code that probably doesnt make sense, this is for you to get started with.\n",
        "\n",
        "## Write your own code and formulate your own approach, feel free to delete this code if you wish, i suggest NOT using it"
      ],
      "metadata": {
        "id": "qEiJV0mJk3YO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-29KdCUhZVK",
        "outputId": "c804f6c1-a801-41f0-d04a-2ba31df505bc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "WjfiE842hZ26"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/selection_competition/train.zip'\n",
        "extract_path = '/content/'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# Step 3: Preprocess the images\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd\n",
        "\n",
        "# Load Data\n",
        "data_dir = '/content/drive/MyDrive/selection_competition/'\n",
        "labels_csv = os.path.join(data_dir, 'train_labels.csv')\n",
        "labels_df = pd.read_csv(labels_csv)\n",
        "\n",
        "\n",
        "# Set the directory where images are extracted\n",
        "data_dir = extract_path\n",
        "\n",
        "# Preprocess Data\n",
        "def preprocess_image(image_path):\n",
        "    try:\n",
        "        image = Image.open(image_path)\n",
        "        image = image.resize((128, 128))\n",
        "        image = np.array(image) / 255.0\n",
        "        return image\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading image {image_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Create Dataset\n",
        "images = []\n",
        "labels = []\n",
        "for i, row in labels_df.iterrows():\n",
        "    if i >= 500:\n",
        "        break\n",
        "    image_path = os.path.join(data_dir+\"train/\", row['id'] + '.tif')\n",
        "    if os.path.exists(image_path):\n",
        "        image = preprocess_image(image_path)\n",
        "        if image is not None:\n",
        "            images.append(image)\n",
        "            labels.append(row['label'])\n",
        "    else:\n",
        "        #print(f\"Image {image_path} does not exist.\")\n",
        "        pass\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Debug: Print the shape of the loaded images and labels\n",
        "print(f\"Loaded {len(images)} images and {len(labels)} labels.\")\n",
        "print(f\"Image shape: {images.shape}\")\n",
        "print(f\"Labels shape: {labels.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gczrfe_9iPTI",
        "outputId": "95b6769d-502f-4551-ee97-84575f134cbe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 500 images and 500 labels.\n",
            "Image shape: (500, 128, 128, 3)\n",
            "Labels shape: (500,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "datagen = ImageDataGenerator(rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True)\n",
        "datagen.fit(images)\n",
        "\n",
        "# Split Data\n",
        "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "fljFKo0Ti19a"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Build Model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train Model\n",
        "model.fit(datagen.flow(X_train, y_train, batch_size=32), validation_data=(X_val, y_val), epochs=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOM7nVsuh0we",
        "outputId": "e20a121d-4368-42a3-e40a-386d487295f0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "13/13 [==============================] - 14s 889ms/step - loss: 2.3026 - accuracy: 0.4825 - val_loss: 0.6683 - val_accuracy: 0.6000\n",
            "Epoch 2/2\n",
            "13/13 [==============================] - 12s 885ms/step - loss: 0.7077 - accuracy: 0.5825 - val_loss: 0.5520 - val_accuracy: 0.8200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d948ec3fe20>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Reshape, Dense, Flatten, Dropout, Activation\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization, LeakyReLU, UpSampling2D, Conv2D\n",
        "\n",
        "# Build Generator\n",
        "def build_generator():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128 * 32 * 32, activation=\"relu\", input_dim=100))\n",
        "    model.add(Reshape((32, 32, 128)))\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n",
        "    model.add(Activation(\"tanh\"))\n",
        "    return model\n",
        "\n",
        "# Build Discriminator\n",
        "def build_discriminator():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=(128, 128, 3), padding=\"same\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "# Compile GAN\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "gan_input = Input(shape=(100,))\n",
        "generated_image = generator(gan_input)\n",
        "discriminator.trainable = False\n",
        "gan_output = discriminator(generated_image)\n",
        "\n",
        "gan = Model(gan_input, gan_output)\n",
        "gan.compile(loss='binary_crossentropy', optimizer='adam')\n"
      ],
      "metadata": {
        "id": "ekQTj1vdj3QV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch_geometric\n"
      ],
      "metadata": {
        "id": "iB9d104Ekocw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# Example data preparation for GCN\n",
        "edge_index = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]], dtype=torch.long)  # Example edge index\n",
        "x = torch.tensor([[1], [1], [1]], dtype=torch.float)  # Example node features\n",
        "\n",
        "# Define GCN\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(1, 16)\n",
        "        self.conv2 = GCNConv(16, 2)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return nn.LogSoftmax(dim=1)(x)\n",
        "\n",
        "# Prepare data for GCN\n",
        "data = Data(x=x, edge_index=edge_index)\n",
        "\n",
        "# Train GCN\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GCN().to(device)\n",
        "data = data.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model.train()\n",
        "for epoch in range(200):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = criterion(out, torch.tensor([0, 1, 0], dtype=torch.long).to(device))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_ojorI0kSnv",
        "outputId": "3ad82896-7ef6-4a95-be28-8d2d2f079b8c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Training\n"
          ]
        }
      ]
    }
  ]
}